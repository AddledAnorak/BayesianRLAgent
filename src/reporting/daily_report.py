"""
Daily report generator - creates human-readable summaries of discoveries and beliefs
"""

import os
import json
from datetime import datetime
from typing import Dict, List, Any
import pandas as pd


class DailyReporter:
    """Generates daily reports of agent discoveries and belief updates"""
    
    def __init__(self, reports_dir: str = "reports"):
        self.reports_dir = reports_dir
        os.makedirs(reports_dir, exist_ok=True)
    
    def generate_report(self, data: Dict[str, Any]) -> str:
        """Generate a comprehensive daily report"""
        timestamp = datetime.now()
        date_str = timestamp.strftime("%Y-%m-%d")
        filename = f"daily_report_{date_str}.md"
        filepath = os.path.join(self.reports_dir, filename)
        
        report_content = self._create_report_content(data, timestamp)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # Also save raw data as JSON
        json_filename = f"daily_data_{date_str}.json"
        json_filepath = os.path.join(self.reports_dir, json_filename)
        
        # Prepare data for JSON (convert objects to dicts)
        json_data = self._prepare_json_data(data)
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, default=str)
        
        print(f"üìÑ Report saved to: {filepath}")
        print(f"üìä Raw data saved to: {json_filepath}")
        
        return filepath
    
    def _create_report_content(self, data: Dict[str, Any], timestamp: datetime) -> str:
        """Create markdown report content"""
        date_str = timestamp.strftime("%B %d, %Y")
        
        report = f"""# Bayesian RL Agent Daily Report
## {date_str}

*Generated at {timestamp.strftime("%H:%M UTC")}*

---

## üìà Executive Summary

"""
        
        # Executive summary
        cycle_results = data.get("cycle_results", {})
        belief_summary = data.get("belief_summary", {})
        
        report += f"""
- **Papers discovered:** {cycle_results.get('papers_found', 0)}
- **Repositories analyzed:** {cycle_results.get('repos_found', 0)}
- **Belief updates:** {cycle_results.get('beliefs_updated', 0)}
- **New techniques tracked:** {cycle_results.get('new_techniques', 0)}
- **Total techniques in knowledge base:** {belief_summary.get('total_techniques', 0)}

"""
        
        # Current beliefs section
        if belief_summary:
            report += self._create_beliefs_section(belief_summary)
        
        # Discoveries section
        papers = data.get("papers", [])
        repos = data.get("repos", [])
        
        if papers:
            report += self._create_papers_section(papers)
        
        if repos:
            report += self._create_repos_section(repos)
        
        # Evidence section
        evidence = data.get("evidence", [])
        if evidence:
            report += self._create_evidence_section(evidence)
        
        # Methodology note
        report += """
---

## üî¨ Methodology Note

This report is generated by a Bayesian RL agent that:

1. **Discovers** new papers from ArXiv and repositories from GitHub
2. **Analyzes** content using NLP to identify RL techniques and effectiveness indicators  
3. **Updates** probabilistic beliefs about technique effectiveness using Bayesian methods
4. **Reports** findings with confidence intervals and uncertainty estimates

Beliefs are represented as Beta distributions, with effectiveness scores from 0-1 and certainty measures based on evidence quantity and quality.

---

*ü§ñ Generated automatically by Bayesian RL Agent*
"""
        
        return report
    
    def _create_beliefs_section(self, belief_summary: Dict) -> str:
        """Create the current beliefs section"""
        section = """
## üéØ Current Beliefs About RL Techniques

### Most Promising Techniques
"""
        
        if "most_promising" in belief_summary and belief_summary["most_promising"]:
            for i, tech in enumerate(belief_summary["most_promising"][:5], 1):
                section += f"{i}. **{tech}**\n"
        else:
            section += "*No high-confidence beliefs yet*\n"
        
        section += "\n### Most Overhyped Techniques\n"
        
        if "most_overhyped" in belief_summary and belief_summary["most_overhyped"]:
            for i, tech in enumerate(belief_summary["most_overhyped"][:3], 1):
                section += f"{i}. **{tech}** *(needs more evidence)*\n"
        else:
            section += "*No overhyped techniques identified*\n"
        
        section += "\n### Need More Evidence\n"
        
        if "most_uncertain" in belief_summary and belief_summary["most_uncertain"]:
            for i, tech in enumerate(belief_summary["most_uncertain"][:3], 1):
                section += f"{i}. **{tech}**\n"
        else:
            section += "*All tracked techniques have reasonable evidence*\n"
        
        # Top 10 ranking
        if "top_10_ranking" in belief_summary and belief_summary["top_10_ranking"]:
            section += "\n### Full Effectiveness Ranking\n\n"
            section += "| Rank | Technique | Effectiveness |\n"
            section += "|------|-----------|---------------|\n"
            
            for i, (tech, eff) in enumerate(belief_summary["top_10_ranking"][:10], 1):
                section += f"| {i} | {tech} | {eff} |\n"
        
        section += "\n"
        return section
    
    def _create_papers_section(self, papers: List) -> str:
        """Create the papers discovery section"""
        section = f"""
## üì∞ Papers Discovered ({len(papers)} total)

"""
        
        # Show top 5 most recent/interesting papers
        sorted_papers = sorted(papers, key=lambda p: p.published_date, reverse=True)
        
        for paper in sorted_papers[:5]:
            # Truncate long titles and abstracts
            title = paper.title if len(paper.title) <= 80 else paper.title[:77] + "..."
            abstract = paper.abstract if len(paper.abstract) <= 200 else paper.abstract[:197] + "..."
            
            section += f"""
### {title}

**Authors:** {', '.join(paper.authors[:3])}{'...' if len(paper.authors) > 3 else ''}  
**Published:** {paper.published_date.strftime('%Y-%m-%d')}  
**Categories:** {', '.join(paper.categories)}  
**URL:** [{paper.url}]({paper.url})

{abstract}

---
"""
        
        if len(papers) > 5:
            section += f"\n*...and {len(papers) - 5} more papers*\n"
        
        return section
    
    def _create_repos_section(self, repos: List) -> str:
        """Create the repositories discovery section"""
        section = f"""
## üîç Repositories Discovered ({len(repos)} total)

"""
        
        # Show top repos by stars
        sorted_repos = sorted(repos, key=lambda r: r.stars, reverse=True)
        
        for repo in sorted_repos[:5]:
            description = repo.description if repo.description and len(repo.description) <= 150 else (repo.description[:147] + "..." if repo.description else "*No description*")
            
            section += f"""
### [{repo.name}]({repo.url})

**Full name:** {repo.full_name}  
**Language:** {repo.language}  
**Stars:** ‚≠ê {repo.stars} | **Forks:** üç¥ {repo.forks}  
**Updated:** {repo.updated_at.strftime('%Y-%m-%d')}  
**Topics:** {', '.join(repo.topics[:5])}{'...' if len(repo.topics) > 5 else ''}

{description}

---
"""
        
        if len(repos) > 5:
            section += f"\n*...and {len(repos) - 5} more repositories*\n"
        
        return section
    
    def _create_evidence_section(self, evidence: List) -> str:
        """Create the evidence extraction section"""
        section = f"""
## üìä Evidence Extracted ({len(evidence)} pieces)

"""
        
        # Group evidence by technique
        evidence_by_tech = {}
        for ev in evidence:
            tech = ev.technique
            if tech not in evidence_by_tech:
                evidence_by_tech[tech] = []
            evidence_by_tech[tech].append(ev)
        
        # Show top techniques by evidence count
        sorted_techniques = sorted(evidence_by_tech.items(), 
                                 key=lambda x: len(x[1]), reverse=True)
        
        for tech, tech_evidence in sorted_techniques[:10]:
            section += f"""
### {tech} ({len(tech_evidence)} evidence pieces)

"""
            # Show a few example evidence pieces
            for ev in tech_evidence[:3]:
                value_desc = "Positive" if ev.value > 0.6 else "Negative" if ev.value < 0.4 else "Neutral"
                confidence_desc = "High" if ev.confidence > 0.7 else "Medium" if ev.confidence > 0.4 else "Low"
                
                section += f"- **{value_desc}** evidence ({confidence_desc} confidence) from {ev.source}\n"
            
            if len(tech_evidence) > 3:
                section += f"- *...and {len(tech_evidence) - 3} more pieces*\n"
            
            section += "\n"
        
        return section
    
    def _prepare_json_data(self, data: Dict[str, Any]) -> Dict:
        """Prepare data for JSON serialization"""
        json_data = {}
        
        # Convert paper objects to dicts
        if "papers" in data:
            json_data["papers"] = [paper.to_dict() for paper in data["papers"]]
        
        # Convert repo objects to dicts  
        if "repos" in data:
            json_data["repos"] = [repo.to_dict() for repo in data["repos"]]
        
        # Convert evidence objects to dicts
        if "evidence" in data:
            json_data["evidence"] = [ev.to_dict() for ev in data["evidence"]]
        
        # Copy other data as-is
        for key, value in data.items():
            if key not in ["papers", "repos", "evidence"]:
                json_data[key] = value
        
        return json_data


if __name__ == "__main__":
    # Example usage
    reporter = DailyReporter()
    
    # Mock data for testing
    mock_data = {
        "cycle_results": {
            "papers_found": 5,
            "repos_found": 3,
            "beliefs_updated": 8,
            "new_techniques": 2
        },
        "belief_summary": {
            "total_techniques": 15,
            "most_promising": ["PPO", "SAC", "TD3"],
            "most_overhyped": ["Ancient Algorithm"],
            "most_uncertain": ["New Technique"]
        },
        "papers": [],
        "repos": [],
        "evidence": []
    }
    
    report_file = reporter.generate_report(mock_data)
    print(f"Example report generated: {report_file}") 